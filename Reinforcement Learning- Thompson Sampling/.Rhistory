print("Hello World!")
6+9
setwd("~/Documents/Machine Learning/Git/ML_AI_Practice_Projects/UCB")
dataset = read.csv('Ads_CTR_Optimisation.csv')
dim(dataset)
dim(dataset[1])
dim(dataset[,1])
dim(dataset[:1])
dim(dataset[:,1])
dim(dataset[1,])
dim(dataset)[1]
a = 10
a + 1
a
a = a + 1
a
a += 1
dataset[2,3]
dataset[2,9]
View(dataset)
# Implementing the UCB
N = dim(dataset)[1]
d = dim(dataset)[2]
ads_selected = integer(0)
number_of_selections = integer(d)
sum_of_rewards = integer(d)
total_reward = 0
for (n in 1:N) {
max_upper_bound = 0
ad = 0
for (i in 1:d){
if (number_of_selections[i] > 0){
average_reward = sum_of_rewards[i]/ number_of_selections[i]
delta_i = sqrt(3/2 * log(n)/ number_of_selections[i])
upper_bound = average_reward + delta_i
} else {
upper_bound = 1e400
}
if (upper_bound > max_upper_bound){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
number_of_selections[ad] = number_of_selections[ad] + 1
sum_of_rewards[ad] = sum_of_rewards[ad] + dataset[n, ad]
total_reward = total_reward + dataset[n,ad]
}
View(ads_selected)
# Implementing the UCB
N = dim(dataset)[1]
d = dim(dataset)[2]
ads_selected = integer(0)
number_of_selections = integer(d)
sum_of_rewards = integer(d)
total_reward = 0
for (n in 1:N) {
max_upper_bound = 0
ad = 0
for (i in 1:d){
if (number_of_selections[i] > 0){
average_reward = sum_of_rewards[i]/ number_of_selections[i]
delta_i = sqrt(3/2)* log(n)/ number_of_selections[i]
upper_bound = average_reward + delta_i
} else {
upper_bound = 1e400
}
if (upper_bound > max_upper_bound){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
number_of_selections[ad] = number_of_selections[ad] + 1
sum_of_rewards[ad] = sum_of_rewards[ad] + dataset[n, ad]
total_reward = total_reward + dataset[n,ad]
}
hist(ads_selected)
# Visualising the results
hist(ads_selected,
col = 'blue',
main = 'Histogram of ads selection',
xlab = 'Ads',
ylab = 'Click count')
# Importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Implementing the UCB
N = dim(dataset)[1]
d = dim(dataset)[2]
ads_selected = integer(0)
number_of_selections = integer(d)
sum_of_rewards = integer(d)
total_reward = 0
for (n in 1:N) {
max_upper_bound = 0
ad = 0
for (i in 1:d){
if (number_of_selections[i] > 0){
average_reward = sum_of_rewards[i]/ number_of_selections[i]
delta_i = sqrt(3/2* log(n)/ number_of_selections[i])
upper_bound = average_reward + delta_i
} else {
upper_bound = 1e400
}
if (upper_bound > max_upper_bound){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
number_of_selections[ad] = number_of_selections[ad] + 1
sum_of_rewards[ad] = sum_of_rewards[ad] + dataset[n, ad]
total_reward = total_reward + dataset[n,ad]
}
# Visualising the results
hist(ads_selected,
col = 'blue',
main = 'Histogram of ads selection',
xlab = 'Ads',
ylab = 'Click count')
setwd("~/Documents/Machine Learning/Git/ML_AI_Practice_Projects/Reinforcement Learning- Thompson Sampling")
